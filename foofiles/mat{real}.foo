!-------------------------------------------------------------------------------
!
! MAT{REAL}: Matrix operations ...
!
! Copyright (C) Dylan Jayatilaka, 1996
!
! This library is free software; you can redistribute it and/or
! modify it under the terms of the GNU Library General Public
! License as published by the Free Software Foundation; either
! version 2 of the License, or (at your option) any later version.
!
! This library is distributed in the hope that it will be useful,
! but WITHOUT ANY WARRANTY; without even the implied warranty of
! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
! Library General Public License for more details.
!
! You should have received a copy of the GNU Library General Public
! License along with this library; if not, write to the
! Free Software Foundation, Inc., 59 Temple Place - Suite 330,
! Boston, MA  02111-1307, USA.
!
! $Id$
!-------------------------------------------------------------------------------

module MAT{REAL}

   implicit none

   interface trace_of_product_with
     trace_product_with
   end

   interface diagonal_set_to
      set_diagonal_to
   end

   interface diagonal_plus
      increment_diagonal_by
   end

   interface diagonal_times
      scale_diagonal_by
   end

   interface diagonal_max 
      max_diagonal_element 
   end

   interface diagonal_max_abs
      max_abs_diagonal_element 
   end

contains

! *****************
! Memory allocation
! *****************

   create(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a matrix with the given dimensions
      self :: PTR
      dim1,dim2 :: INT, IN
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a matrix with the specified "bounds" for each dimension
      self :: PTR
      bounds :: VEC{INT}(2), IN
   end

   create(lb1,ub1,lb2,ub2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a matrix with the given dimensions
      self :: PTR
      lb1,ub1,lb2,ub2 :: INT, IN
   end

   create(bounds1,bounds2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a matrix with the specified bounds for each dimension
      self :: PTR
      bounds1,bounds2 :: VEC{INT}, IN
   end

   create(bounds) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a matrix with the given bounds for all dimensions
      self :: PTR
      bounds :: MAT{INT}(2,2), IN
   end

   create_copy(matrix) ::: get_from(MAT{INTRINSIC}), leaky
   ! Create a replica copy of matrix
      self :: PTR
      matrix :: MAT{REAL}, IN
   end

   destroy ::: get_from(MAT{INTRINSIC}), leaky
   ! Destroy the object
      self :: PTR
   end

   created result(res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo
   ! Returns true if self has been created
      self :: PTR
      res :: BIN
   end

   destroyed result(res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo
   ! Returns true if self has *not* been created
      self :: PTR
      res :: BIN
   end

! ****************************
! Size-of and shape operations 
! ****************************

   size result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo
   ! Return the size of the array
      res :: INT
   end

   dim1 result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo
   ! Return the size of the 1st dimension
      res :: INT
   end

   dim2 result (res) ::: get_from(MAT{INTRINSIC}), inlined_by_foo
   ! Return the size of the 2nd dimension
      res :: INT
   end

   shape result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the shape of "self"
      res :: VEC{INT}(2)
   end

   is_same_shape_as(a) result(res) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" has the same shape as "self"
      self :: IN
      a :: MAT{REAL}, IN
      res :: BIN
   end

   is_transposed_shape_of(a) result(res) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}), pure
   ! Returns TRUE if the matrix "a" is the transposed shape of self
      self :: IN
      a :: MAT{REAL}, IN
      res :: BIN
   end

   is_square result(res) ::: get_from(MAT{INTRINSIC}), pure
   ! Returns TRUE if the matrix is square
      self :: IN
      res :: BIN
   end

! ***********************
! Shrinking and expansion
! ***********************

   shrink(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Shrinks self to dimension dim1xdim2.  Contents are retained.
     self :: PTR
     dim1,dim2 :: INT, IN
   end

   expand(dim1,dim2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Expands self to dimension dim1xdim2.  Contents are retained.
     self :: PTR
     dim1,dim2 :: INT, IN
   end

   shrink_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Shrinks columns of self to dimension dim2. Contents are retained.
     self :: PTR
     dim2 :: INT, IN
   end

   expand_columns(dim2) ::: get_from(MAT{INTRINSIC}), leaky
   ! Expands the columns self to dim2.  Contents are retained.
     self :: PTR
     dim2 :: INT, IN
   end

   append_columns(cols) ::: get_from(MAT{INTRINSIC}), leaky
   ! Append the columns "cols" onto the end of self.
     self :: PTR
     cols :: MAT{REAL}
   end

   append_column(col) ::: get_from(MAT{INTRINSIC}), leaky
   ! Append the column "col" onto the end of self.
     self :: PTR
     col :: VEC{REAL}
   end

! ********************
! Comparison functions
! ********************

   equals(b) result(res) ::: get_from(MAT{INTRINSIC})
   ! Check if the matrix is the same as "b".
      self :: IN
      b :: MAT{REAL}, IN
      res :: BIN
   end

   same_as(b,eps,diff) result(res) ::: get_from(MAT{INTRINSIC})
   ! Check if the matrix is the same as "b", within "eps", and return the
   ! actual difference in "diff"
      self :: IN
      b :: MAT{REAL}, IN
      eps :: REAL, IN, optional
      diff :: REAL, OUT, optional
      res :: BIN
   end

! ****************
! Range operations
! ****************

   all_in_range(range) result(res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE if all values of self are within the specified "range".
      range :: VEC{REAL}(2)
      res :: BIN
   end

   in_range(range) result(res) ::: get_from(MAT{INTRINSIC})
   ! Return element ij as TRUE if self(i,j) is within the specified "range".
      range :: VEC{REAL}(2)
      res :: MAT{BIN}(.dim1,.dim2)
   end

   range result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the range (smallest and largest value) of self.
      res :: VEC{REAL}(2)
   end

! *****************
! Inquiry functions
! *****************

   is_diagonal result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is a diagonal matrix
      self :: IN
      res :: BIN
   end

   has_unit_diagonal(eps) result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" has 1's as diagonal elements to within
   ! tolerance "eps" (if present).
      self :: IN
      eps :: REAL, IN, optional
      res :: BIN
   end

   has_minus_unit_diagonal result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" has -1's as diagonal elements
      self :: IN
      res :: BIN
   end

   is_unit_matrix result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is the unit matrix
      self :: IN
      res :: BIN
   end

   is_inversion_matrix result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is an inversion matrix
   ! i.e. minus the unit matrix
      self :: IN
      res :: BIN
   end

   is_symmetric result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is a symmetric matrix
      self :: IN
      res :: BIN
   end

   is_antisymmetric result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" is an antisymmetric matrix
      self :: IN
      res :: BIN
   end

   is_zero(eps) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE is "self" is the zero matrix, i.e. every element is zero.
   ! If present, "eps" is used to decide when a small number is zero.
      eps :: REAL, optional, IN
      res :: BIN
   end

! *****************
! Column operations 
! *****************

   has_column(c,eps,col) result(res) ::: get_from(MAT{INTRINSIC})
   ! Returns TRUE if the matrix "self" has a column "c", with "eps" tolerance.
   ! If present, the matching column index "col" is also returned.
      self :: IN
      c :: VEC{REAL}, IN
      eps :: REAL, optional
      col :: INT, optional
      res :: BIN
   end

   column_index(c,eps) result(res) ::: get_from(MAT{INTRINSIC})
   ! The matching column index is returned, if the column matches "col" to
   ! tolerance "eps", if it is present.
      self :: IN
      c :: VEC{REAL}, IN
      res :: INT
      eps :: REAL, optional
   end

   compare_columns_with(m,col) ::: get_from(MAT{INTRINSIC})
   ! Compare the columns of "self" with "m". The elements of array "col" are set
   ! TRUE if the corresponding column appears in "m"
      self :: IN
      m :: MAT{REAL}, IN
      col :: VEC{INT}, OUT
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC})
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set TRUE if the corresponding
   ! column is unique.
   end

   unique_columns(col) ::: get_from(MAT{INTRINSIC}), leaky
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. The elements of array "col" are set to the indices of the unique
   ! columns.
   end

   no_of_unique_columns result (res) ::: get_from(MAT{INTRINSIC})
   ! Compare the later columns of "self" with earlier columns to see if they are
   ! unique. Return the number of unique columns.
   end

   swap_columns(col1,col2) ::: get_from(MAT{INTRINSIC})
   ! Swap columns "col1" and "col2" of self
      col1,col2 :: INT, IN
   end

   swap_columns(list) ::: get_from(MAT{INTRINSIC})
   ! Sequentially swap all columns in a column "list",
   ! self(:,i)      = self(:,list(i))
   ! self(:,col(i)) = self(:,i)
      list :: VEC{INT}, IN
   end

   column_norms result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
      res :: VEC{REAL}(.dim2)
   end

   get_column_norms(res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every column
      res :: VEC{REAL}
   end

   get_column_dot_products(res) ::: get_from(MAT{INTRINSIC})
   ! Return the dot products of every column with itself.
   ! Good for testing distances without using a sqrt.
      res :: VEC{REAL}
   end

   index_of_minimum_column_norm(offset) result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the column index of the column with the *minimum* norm. If present,
   ! "offset" is subtracted from every column beforehand, and then added back
   ! afterwards. This is useful for finding the index of the column with minimum
   ! distance to "offset", for a list of points held in "self".
      offset :: VEC{REAL}(.dim1), optional
      res :: INT
   end

   max_abs_column_difference result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the maximum of the absolute difference between all the column vector
   ! pairs of the matrix.
      res :: VEC{REAL}(.dim1)
   end

   mean_column_vector result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the mean of the column vectors.
      res :: VEC{REAL}(.dim1)
   end

   sum_column_vectors result(res) ::: get_from(MAT{INTRINSIC})
   ! Sum the column vectors (i.e. rows) in "self".
      res :: VEC{REAL}(.dim1)
   end

   reverse_column_order ::: get_from(MAT{INTRINSIC})
   ! Reverse the order of the columns of self.
   end

! **************
! Row operations
! **************

   unique_rows(row) ::: get_from(MAT{INTRINSIC})
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set TRUE if the corresponding
   ! row is unique.
   end

   unique_rows(row) ::: get_from(MAT{INTRINSIC}), leaky
   ! Compare the later rows of "self" with earlier rows to see if they are
   ! unique. The elements of array "row" are set to the indices of the unique
   ! rows.
   end

   no_of_unique_rows result (res) ::: get_from(MAT{INTRINSIC})
   ! Compare the later row of "self" with earlier rows to see if they are
   ! unique. Return the number of unique rows.
   end

   swap_rows(row1,row2) ::: get_from(MAT{INTRINSIC})
   ! Swap columns "row1" and "row2" of self
      row1,row2 :: INT, IN
   end

   swap_rows(list) ::: get_from(MAT{INTRINSIC})
   ! Sequentially swap all rows in a row "list",
   ! self(i,:)       = self(list(i),:)
   ! self(list(i),:) = self(i,:)
   end

   row_norms result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the norms of every row
      res :: VEC{REAL}(.dim1)
   end

   sum_row_vectors result(res) ::: get_from(MAT{INTRINSIC})
   ! Sum the row vectors (i.e. columns) in "self".
      res :: VEC{REAL}(.dim2)
   end

! ******************************************
! Matrix algebra and vector space operations
! ******************************************

   determinant result(res) ::: get_from(MAT{INTRINSIC})
   ! Return the determinant a 3x3 matrix
      self :: IN
      res :: REAL
   end

   cofactor result(res) ::: get_from(MAT{INTRINSIC}), leaky
   ! Return the cofactor of a 3x3 matrix
      self :: IN
      res :: MAT{REAL}*
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>VEC{REAL}, RES_TYPE=>REAL)
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
     self :: IN
     l,r :: VEC{REAL}, IN
     res :: REAL
   end

   dot(l,r) result (res) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>VEC{CPX}, RES_TYPE=>CPX)
   ! Multiply the matrix self by vector "l" on the left and vector "r" on the
   ! right ie:  res = l^dagger self r. Useful for non-unit metric dot_products.
     self :: IN
     l,r :: VEC{CPX}, IN
     res :: CPX
   end

   rotate(v) ::: get_from(MAT{INTRINSIC})
   ! Rotate vector "v" by self
     v :: VEC{REAL}, INOUT
   end

!   rotate_by_jacobi(p,q,u_pp,u_pq)
!   ! Do a two dimensional Jacobi rotation in the plane pq with the rotation
!   ! matrix u with elements u_pp and u_pq.
!      p,q :: INT
!      u_pp,u_pq :: REAL
!      n :: INT
!      row_p, row_q, col_p, col_q :: VEC{REAL}*
!      n = self.dim1
!      row_p.create(n)
!      row_q.create(n)
!      col_p.create(n)
!      col_q.create(n)
!      row_p  = u_pp*self(p,:) + u_pq*self(q,:)
!      row_q  = - u_pq*self(p,:) + u_pp*self(q,:)
!      self(p,:) = row_p
!      self(q,:) = row_q
!      col_p = u_pp*self(:,p) + u_pq*self(:,q)
!      col_q = u_pp*self(:,q) - u_pq*self(:,p)
!      self(:,q) = col_q
!      self(:,p) = col_p
!      row_p.destroy; row_q.destroy; col_p.destroy; col_q.destroy
!   end

!   rotate_by_jacobi(p,q,u_pp,u_pq)
!   ! Do a two dimensional Jacobi rotation in the plane pq with the rotation
!   ! matrix u with elements u_pp and u_pq, i.e. self = u . self . u^T
!   ! where the only non-zero elements of u are u_pp, u_pq, u_qp=-u_pq, and
!   ! u_qq=u_pp
!      self :: target
!      p,q :: INT
!      u_pp,u_pq :: REAL
!      n :: INT
!      row_p,row_q,col_p,col_q,self_p,self_q :: VEC{REAL}*
!      n = self.dim1
!      row_p.create(n); row_q.create(n)
!      col_p.create(n); col_q.create(n)
!      self_p => self(p,:)
!      self_q => self(q,:)
!      row_p  =  u_pp*self_p + u_pq*self_q
!      row_q  = -u_pq*self_p + u_pp*self_q
!      self_p = row_p
!      self_q = row_q
!      self_p => self(:,p)
!      self_q => self(:,q)
!      col_p =  u_pp*self_p + u_pq*self_q
!      col_q = -u_pq*self_p + u_pp*self_q
!      self_q = col_q
!      self_p = col_p
!      row_p.destroy; row_q.destroy
!      col_p.destroy; col_q.destroy
!   end

   jacobi_rotation(p,q)
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q). NOTE: self must be symmetric
      p,q :: INT
      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL
      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)
      theta = (s_qq-s_pp)/(TWO*s_pq) 
      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t
      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)
      do i = 1,.dim1
         s_ip = self(i,p)
         s_iq = self(i,q)
         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)
         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq
      end
      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO
   end

   jacobi_rotation(p,q,v)
   ! Do a two dimensional Jacobi rotation in the plane of "p" and "q" so as to
   ! eliminate the off diagonal element self(p,q) and also update the rotation
   ! matrix "v". NOTE: self must be symmetric
      p,q :: INT
      v :: MAT{REAL}
      i :: INT
      s_pp,s_qq,s_pq,theta,t,c,s,tau,s_ip,s_iq,r_ip,r_iq :: REAL
      s_pp = self(p,p)
      s_qq = self(q,q)
      s_pq = self(p,q)
      theta = (s_qq-s_pp)/(TWO*s_pq) 
      t = ONE/(abs(theta)+sqrt(theta*theta+ONE))
      if (theta<ZERO) t = -t
      c = ONE/sqrt(t*t+ONE)
      s = t*c
      tau = s/(ONE+c)
      do i = 1,.dim1
         s_ip = self(i,p)
         s_iq = self(i,q)
         r_ip = s_ip - s*(s_iq+tau*s_ip)
         r_iq = s_iq + s*(s_ip-tau*s_iq)
         self(i,p) = r_ip
         self(p,i) = r_ip
         self(i,q) = r_iq
         self(q,i) = r_iq
      end
      self(p,p) = s_pp - t*s_pq
      self(q,q) = s_qq + t*s_pq
      self(p,q) = ZERO
      self(q,p) = ZERO
      do i = 1,.dim1
         s_ip = v(i,p)
         s_iq = v(i,q)
         v(i,p) = s_ip - s*(s_iq+tau*s_ip)
         v(i,q) = s_iq + s*(s_ip-tau*s_iq)
      end
   end

   to_unit_matrix ::: get_from(MAT{INTRINSIC})
   ! Set "self" to the unit matrix
   end

   to_3x3_rotation_matrix(axis,angle) 
   ! Set "self" to the rotation matrix which rotates around vector "axis" in
   ! an anticlockwise direction (when looking against the "axis" vector) by
   ! amount "angle" (in radians).
      axis :: VEC{REAL}, IN
      angle :: REAL, IN
   ENSURE(.is_square,"non-square matrix")
   ENSURE(.dim1==3,"must be 3x3 matrix")
   ENSURE(axis.dim==3,"axis is not 3 dimensional")
      x,y,z,xp,yp :: VEC{REAL}(3)
      z = axis
      z.normalise
      x = z.cross([ONE,ZERO,ZERO])
      if (x.is_zero(TOL(9))) x = z.cross([ZERO,ONE,ZERO])
      x.normalise 
      y = z.cross(x)
      xp = cos(angle)*x+sin(angle)*y
      yp = cos(angle)*y-sin(angle)*x
      self =  z.outer_product_with(z) &
           + xp.outer_product_with(x) &
           + yp.outer_product_with(y) 
   end

   zero_small_values(eps) ::: get_from(MAT{INTRINSIC}), pure
   ! Zero elements of the matrix which are less than "eps" in magnitude
      self :: INOUT
      eps :: REAL, IN
   end

   set_to(a) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Set self to "a"
      a :: MAT{REAL}, IN
   ENSURE(.is_same_shape_as(a),"incompatible shape")
   end

   set_to_transpose_of(a) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Self becomes the transpose of "a"
     self :: OUT
     a :: MAT{REAL}, IN
   end

   to_transpose ::: get_from(MAT{INTRINSIC})
   ! Self becomes its own transpose.
     self :: INOUT
   end

   plus(a) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Add to self the matrix "a"
      a :: MAT{REAL}, IN
   end

   minus(a) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Subtract from self the matrix "a"
      a :: MAT{REAL}, IN
   end

   to_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}, FAC_TYPE=>REAL)
   ! Set "self" to matrix "at" scaled by "fac"
      self :: OUT
      a :: MAT{REAL}, IN
      fac :: REAL, IN
   end

   plus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}, FAC_TYPE=>REAL)
   ! Add to "self" matrix "a" scaled by "fac"
      self :: INOUT
      a :: MAT{REAL}, IN
      fac :: REAL, IN
   end

   minus_scaled(a,fac) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}, FAC_TYPE=>REAL)
   ! Subtract from "self" matrix "a" scaled by "fac"
      self :: INOUT
      a :: A_TYPE, IN
      fac :: FAC_TYPE, IN
   end

   to_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB_TYPE=>MAT{REAL})
   ! Set "self" to the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
     self :: OUT
     a,b :: MAT{REAL}, IN
     transpose_a, transpose_b :: BIN, optional, IN
   end

   plus_product_of(a,b,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB_TYPE=>MAT{REAL})
   ! Add to "self" the matrix product of "a" and "b". If present, "transpose_a"
   ! and "transpose_b" can be set to TRUE if "a" and "b" need to be transposed.
     self :: INOUT
     a,b :: MAT{REAL}, IN
     transpose_a, transpose_b :: BIN, optional, IN
   end

   to_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB_TYPE=>MAT{REAL}, FAC_TYPE=>REAL)
   ! Set "self" to the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! need to be transposed.
     self :: OUT
     a,b :: MAT{REAL}, IN
     fac :: REAL
     transpose_a, transpose_b :: BIN, optional, IN
   end

   plus_scaled_product_of(a,b,fac,transpose_a,transpose_b) ::: get_from(MAT{INTRINSIC}, AB_TYPE=>MAT{REAL}, FAC_TYPE=>REAL)
   ! Add to "self" the matrix product of "a" and "b" scaled by "fac". If
   ! present, "transpose_a" and "transpose_b" can be set to TRUE if "a" and "b"
   ! neeb to be transposed.
     self :: INOUT
     a,b :: MAT{REAL}, IN
     fac :: REAL
     transpose_a, transpose_b :: BIN, optional, IN
   end

   to_product_with_diagonal(a,diag,transpose_a) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL}, DIAG_TYPE=>VEC{REAL})
   ! Set "self" to the matrix product of "a" with diagonal matrix "diag" (stored
   ! as a vector).  If present, ""transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
      self :: INOUT
      a :: MAT{REAL}, IN
      diag :: VEC{REAL}, IN
      transpose_a :: BIN, optional, IN
   end

   to_product_with_diagonal(dg,a,transpose_a) ::: get_from(MAT{INTRINSIC}, DG_TYPE=>VEC{REAL}, A_TYPE=>MAT{REAL})
   ! Set "self" to the matrix product of diagonal matrix "dg" (stored as a
   ! vector) and "a".  If present, "transpose_a" can be set to TRUE if "a" needs
   ! to be transposed.
      self :: OUT
      dg :: VEC{REAL}, IN
      a :: MAT{REAL}, IN
      transpose_a :: BIN, optional, IN
   end

! ****************
! Trace operations
! ****************

   trace result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the trace of self
      self :: IN
      res :: REAL
   end

   trace_product_with(a) result (res) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Return the trace of the product of "self" with matrix "a".
      self :: IN
      a :: MAT{REAL}, IN
      res :: REAL
   end

   trace_product_with(a,transpose_a) result (res) ::: get_from(MAT{INTRINSIC}, A_TYPE=>MAT{REAL})
   ! Return the trace of the product of "self" with matrix "a",
   ! and if "transpose_a" is present and TRUE, then transpose "a".
   end

   dot(a) result (res) 
   ! Synonym for trace_product_with(a) ... Return the trace of the product of
   ! "self" with matrix "a". This is really intended for use with symmetric
   ! matrices only.
      self :: IN
      a :: MAT{REAL}, IN
      res :: REAL
 ! ENSURE(.is_symmetric,"self is not symmetric")
 ! ENSURE(a.is_symmetric,"self is not symmetric")
      res = .trace_product_with(a,transpose_a=TRUE)
   end

   trace_product_with(a,b,c) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the trace of the product of "self" with matrices "a", "b" and "c".
      a,b,c :: MAT{REAL}
      res :: REAL
   end

   trace_product_with(a,b,c,d,e) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return the trace of the product of "self" with matrices "a", "b" ... "e".
      a,b,c,d,e :: MAT{REAL}
      res :: REAL
   end

! ************************
! Change of basis routines
! ************************

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>MAT{REAL})
   ! Change the basis of "self" using vectors "V"; self = V^dagger self V
      V :: MAT{REAL}, IN
   end

   change_basis_using(V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>VEC{REAL})
   ! Change the basis of "self" using diagonal matrix "V" (stored as a vector).
   ! self = V self V
      V :: VEC{REAL}, IN
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>MAT{REAL})
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
   end

   change_basis_using(L,R) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>VEC{REAL})
   ! Change the basis of "self" using diagonal matrices "L" and "R" (stored as
   ! vectors).  self = L self R
      L,R :: VEC{REAL}, IN
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>MAT{REAL})
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new".  new = V^dagger self V
      self :: IN
      new :: MAT{INTRINSIC}, OUT
      V :: V_TYPE, IN
   end

   change_basis_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW_TYPE=>MAT{CPX}, V_TYPE=>MAT{CPX})
   ! Change the basis of "self" using vectors "V", and place the result in
   ! "new" i.e. new = V^dagger self V. This version uses only intrinsic
   ! procedures to avoid circular dependencies.
      self :: IN
      new :: NEW_TYPE, OUT
      V :: V_TYPE, IN
   end

   change_basis_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>MAT{REAL})
   ! Change the basis of "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L^dagger self R
      self :: IN
      new :: MAT{REAL}, OUT
      L,R :: LR_TYPE, IN
   end

   back_transform_using(V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>MAT{REAL})
   ! Back transform "self" using vectors "V", and place the result in "self".
   ! self = V self V^dagger
      V :: MAT{REAL}, IN
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>MAT{REAL})
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! new = V self V^dagger
      self :: IN
      new :: MAT{REAL}, OUT
      V :: V_TYPE, IN
   end

   back_transform_to(new,V) ::: get_from(MAT{INTRINSIC}, NEW_TYPE=>MAT{CPX}, V_TYPE=>MAT{CPX})
   ! Back transform "self" using vectors "V", and place the result in "new".
   ! i.e. new = V self V^dagger. This version uses only intrinsic calls to avpid
   ! circular dependencies.
      self :: IN
      new :: NEW_TYPE, OUT
      V :: V_TYPE, IN
   end

   back_transform_to(new,L,R) ::: get_from(MAT{INTRINSIC}, LR_TYPE=>MAT{REAL})
   ! Back transform "self" using left and right matrices "L" and "R"
   ! and place the result in "new", new = L self R^dagger
      self :: IN
      new :: MAT{REAL}, OUT
      L,R :: MAT{REAL}, IN
   end

   similarity_transform(V) ::: get_from(MAT{INTRINSIC}, V_TYPE=>MAT{REAL})
   ! Do a similarity transform of "self" using vectors "V": self = V self V^-1
      V :: MAT{REAL}, IN
   end

! **************************
! Operations on the diagonal
! **************************

   set_from_diagonal(d) ::: get_from(MAT{INTRINSIC}, D_TYPE=>VEC{REAL})
   ! Converts the diagonal vector "d" to matrix "self".
      d :: VEC{REAL}
   end

   set_diagonal_to(d) ::: get_from(MAT{INTRINSIC}, D_TYPE=>VEC{REAL})
   ! Set the diagonal of "self" to th diagonal vector "d"
      d :: VEC{REAL}
   end

   set_diagonal_to(val) ::: get_from(MAT{INTRINSIC}, VAL_TYPE=>REAL)
   ! Set the diagonal of "self" to "val"
      val :: REAL
   end

   put_diagonal_to(d) ::: get_from(MAT{INTRINSIC})
   ! Get the diagonal elements of "self" in vector "d"
      d :: VEC{REAL}
   end

   increment_diagonal_by(val) ::: get_from(MAT{INTRINSIC}, VAL_TYPE=>REAL)
   ! Add "val" to the diagonal of "self"
      val :: REAL
   end

   scale_diagonal_by(fac) ::: get_from(MAT{INTRINSIC}, FAC_TYPE=>REAL)
   ! Weight the diagonal elements of "self" by "fac"
      fac :: REAL, IN
   end

   zero_diagonal ::: get_from(MAT{INTRINSIC})
   ! Zero the diagonal elements of "self"
   end

   zero_off_diagonal ::: get_from(MAT{INTRINSIC})
   ! Zero the off diagonal elements of "self"
   end

   max_diagonal_element result (res) ::: get_from(MAT{INTRINSIC})
   ! Get the maximum element on the diagonal of the matrix
      res :: REAL
   end

   max_abs_diagonal_element result (res) ::: get_from(MAT{INTRINSIC})
   ! Get the maximum absolute value of the diagonal elements of the self matrix
      res :: REAL
   end

! ************************
! Symmetrising and folding
! ************************

   symmetrize ::: get_from(MAT{INTRINSIC})
   ! Set self to half of itself plus half its transpose, i.e.
   ! self = 1/2 (self + self^T)
   end

   antisymmetrize ::: get_from(MAT{INTRINSIC})
   ! Set self to half of itself minus half its transpose, i.e.
   ! self = 1/2 (self - self^T)
   end

   symmetric_fold ::: get_from(MAT{INTRINSIC})
   ! Add the upper triangle of "self" into the lower triangle
   end

   antisymmetric_fold ::: get_from(MAT{INTRINSIC})
   ! Subtract the upper triangle of "self" into the lower triangle
   end

   symmetric_reflect ::: get_from(MAT{INTRINSIC})
   ! Make the upper triangle of "self" the same as the lower triangle
   end

   antisymmetric_reflect ::: get_from(MAT{INTRINSIC})
   ! Make the upper triangle of "self" the negative of the lower triangle and
   ! make the diagonal zero.
   end

   symmetric_fold_to_triangle(tr) ::: get_from(MAT{INTRINSIC})
   ! Add the upper triangle of "self" into the lower triangle and return
   ! the lower triangle "tr" as a vector across rows.
      tr :: VEC{REAL}
   end

! **************************************
! Compression and uncompression routines
! **************************************

   compress_to_triangle(tr) ::: get_from(MAT{INTRINSIC})
   ! Converts the lower triangle of matrix self to the triangle "tr".
   ! using row order.
      self :: IN
      tr :: VEC{REAL}
   end

   uncompress_from_triangle(tr) ::: get_from(MAT{INTRINSIC})
   ! Converts the triangle "tr" into the symmetric matrix "self".
      tr :: VEC{REAL}
   end

   tri_size result (ltr) ::: get_from(MAT{INTRINSIC})
   ! Returns the size of the lower triangle needed to store self.
      self :: IN
      ltr :: INT
   end

! *****************
! Orthogonalisation
! *****************

   is_linearly_dependent(S,tol,col) result (res) ::: get_from(MAT{INTRINSIC})
   ! Return TRUE if the columns are linearly dependent with respect to "S".
   ! If present, "tol" is the tolerance used to establish linear dependency.
   ! If present, "col" is the column number where the dependence was first
   ! noticed when Schmidt orthogonalising is used, starting from column 1.
   end

   schmidt_orthonormalise(S,scale) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric. If "scale" is present, it is set to the product of the
   ! normalisation factors used to normalise each column after the Schmidt
   ! procedure.
     self :: target
     S :: MAT{REAL}, IN
     scale :: REAL, optional
   end

   schmidt_orthonormalise(S,from,to) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the *column* vectors in "self" using "S" as the
   ! metric. Only the columns starting from index "from" are orthonormalised,
   ! and further, those columns are only orthonormalised to first columns, up to
   ! the column with index "to".
     self :: target
     S :: MAT{REAL}, IN
     from,to :: INT
   end

   reverse_schmidt_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using "S" as the
   ! metric.
     self :: target
     S :: MAT{REAL}
   end

   schmidt_orthonormalise ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self".
     self :: target
   end

   reverse_schmidt_orthogonalise ::: get_from(MAT{INTRINSIC})
   ! Schmidt orthonormalise the column vectors in "self" using unit metric.
      self :: target
   end

   symmetrically_orthonormalise(S) ::: get_from(MAT{INTRINSIC})
   ! Symmetrically orthonormalise the column vectors in "self" using "S" as the
   ! metric.
     S :: MAT{REAL}, IN
   end

   make_diagonally_dominant(permutation) ::: get_from(MAT{INTRINSIC})
   ! Rearrange the order of the columns of self so that the largest magnitude
   ! elements in each column occur along the diagonal. If "permutation" is
   ! present, it is the array which achieves this ordering, i.e. at the end of
   ! the routine, what is done is: self = self(:,permutation).
      permutation :: VEC{INT}, optional
   end

! *********************
! Eigenproblem routines
! *********************

!   diagonalise_by_jacobi_2(eigenvalues, failure, iter, u, eps, max_iter)
!   ! Diogonalises self using the Jacobi rotations method. Returns the
!   ! eigenvalues and rotation matrix. Input the accuracy if desired.
!     eigenvalues :: VEC{REAL}
!     failure :: BIN
!     iter :: INT
!     u :: MAT{REAL}
!     eps :: REAL, optional
!     max_iter :: INT, optional
!  ENSURE(.is_square, "the matrix is not square")
!  ENSURE(.is_symmetric, "the matrix is not symmetrix")
!  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
!     i,k, max_iter_default  :: INT
!   ! i,k, iter, max_iter_default  :: INT
!     a,b,c,d, u_pp, u_pq, accuracy :: REAL
!     no_rotation :: BIN
!     m :: MAT{REAL}*
!     r_p, r_q :: VEC{REAL}*
!     m.create_copy(self)
!     r_p.create(.dim1)
!     r_q.create(.dim1)
!     accuracy = TOL(12)
!     if (present(eps)) accuracy=eps
!     max_iter_default=1000
!     if (present(max_iter)) max_iter_default=max_iter
!     no_rotation=FALSE
!     iter=-1
!        do i=1,.dim1
!           do k=1,.dim1
!           if (k==i) then
!           u(k,i)=1
!           else 
!           u(k,i)=0
!           end if 
!           end do
!           end do
!
!     do
!        failure = iter>max_iter_default
!        if (failure) exit
!        if (no_rotation) exit
!        no_rotation=TRUE
!        do i=1,.dim1
!        do k=1,(i-1)
!           c = m(i,k)
!           if (abs(c)<accuracy) cycle
!           a = m(i,i)
!           b = m(k,k)
!           no_rotation=FALSE
!           d = (2*c)/(a-b+sqrt((a-b)**2+4*c**2))
!           u_pp = 1/(sqrt(1+d**2))
!           u_pq = d*u_pp
!          m.rotate_by_jacobi(i, k, u_pp, u_pq)      
!      r_p  = u_pp*u(i,:) + u_pq*u(k,:)
!      r_q  = - u_pq*u(i,:) + u_pp*u(k,:)
!      u(i,:) = r_p
!      u(k,:) = r_q
!        end do
!        end do
!        iter=iter+1
!     end do
!     r_p.destroy; r_q.destroy
!     m.put_diagonal_to(eigenvalues)
!     m.destroy
!   end

!   diagonalise_by_jacobi(eigenvalues,eigenvectors,eps,max_iterations)
!   ! Diagonalises "self" using the Jacobi rotations method. Returns the
!   ! "eigenvalues" and "eigenvectors". Input the accuracy "eps" or the
!   ! maximum number of iterations "max_iter", if desired.
!     eigenvalues :: VEC{REAL}
!     eigenvectors :: MAT{REAL}
!     eps :: REAL, optional
!     max_iterations :: INT, optional
!  ENSURE(.is_square, "the matrix is not square")
!  ENSURE(.is_symmetric, "the matrix is not symmetrix")
!  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
!     i,j,iter,max_iter  :: INT
!     c,d,u_ii,u_ij,accuracy,del :: REAL
!     done :: BIN
!     W :: MAT{REAL}*
!     r_i,r_j :: VEC{REAL}*
!     accuracy = TOL(12)
!     if (present(eps)) accuracy = eps
!     max_iter=1000
!     if (present(max_iterations)) max_iter = max_iterations
!     W.create_copy(self)
!     r_i.create(.dim1)
!     r_j.create(.dim1)
!     eigenvectors.to_unit_matrix
!     iter=-1
!     done = FALSE
!     do
!      ! DIE_IF(iter>max_iter,"too many iterations")
!        if (iter>max_iter) exit
!        if (done) exit
!        write(*,*) "iter =",iter
!        write(*,"(a)") "W:"
!        write(*,"(3f12.8)") W
!        done = TRUE
!        do i = 1,.dim1
!        do j = 1,i-1
!           c = W(i,j)
!           if (abs(c)<accuracy) cycle
!           del = W(i,i) - W(j,j)
!           done = FALSE
!           d = TWO*c/(del+sqrt(del*del+FOUR*c*c))
!           u_ii = ONE/(sqrt(ONE+d*d))
!           u_ij = d*u_ii
!           W.rotate_by_jacobi(i,j,u_ii,u_ij)      
!        write(*,"(a,2i3)") "W, ij = ",i,j
!        write(*,"(3f12.8)") W
!           r_i =  u_ii*eigenvectors(i,:) + u_ij*eigenvectors(j,:)
!           r_j = -u_ij*eigenvectors(i,:) + u_ii*eigenvectors(j,:)
!           eigenvectors(i,:) = r_i
!           eigenvectors(j,:) = r_j
!        end
!        end
!        iter = iter + 1
!     end
!     r_i.destroy; r_j.destroy
!     W.put_diagonal_to(eigenvalues)
!     W.destroy
!   end

   diagonalise_by_jacobi(eigenvalues,eps,max_iterations)
   ! Diagonalises "self" using the Jacobi rotations method. Returns the
   ! "eigenvalues". Input the accuracy "eps" or the maximum number of iterations
   ! "max_iter", if desired.
     eigenvalues :: VEC{REAL}
     eps :: REAL, optional
     max_iterations :: INT, optional
  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
     i,j,iter,max_iter  :: INT
     accuracy,tol :: REAL
     done :: BIN
     W :: MAT{REAL}*
     accuracy = TOL(12)
     if (present(eps)) accuracy = eps
     max_iter = 30
     if (present(max_iterations)) max_iter = max_iterations
     W.create_copy(self)
     iter = 0
     do
        iter = iter + 1
        DIE_IF(iter>max_iter,"too many iterations")
        if (iter>max_iter) exit
        tol = accuracy
        if (iter<=3) tol = TOL(1)*(sum(abs(W)) - W.trace)
        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j)      
        end
        end
        done = done AND iter>3
        if (done) exit
     end
     W.put_diagonal_to(eigenvalues)
     W.destroy
   end

   diagonalise_by_jacobi(eigenvalues,eigenvectors,eps,max_iterations)
   ! Diagonalises "self" using the Jacobi rotations method. Returns the
   ! "eigenvalues". Input the accuracy "eps" or the maximum number of iterations
   ! "max_iter", if desired.
     eigenvalues :: VEC{REAL}
     eigenvectors :: MAT{REAL}
     eps :: REAL, optional
     max_iterations :: INT, optional
  ENSURE(.is_square, "self is not square")
  ENSURE(.is_symmetric, "self is not symmetrix")
  ENSURE(eigenvalues.dim==.dim1,"wrong size, eigenvalues")
  ENSURE(eigenvectors.is_square, "eigenvectors are not square")
  ENSURE(eigenvalues.dim1>=.dim1,"wrong size, eigenvectors")
     i,j,iter,max_iter  :: INT
     accuracy,tol :: REAL
     done :: BIN
     W :: MAT{REAL}*
     accuracy = TOL(12)
     if (present(eps)) accuracy = eps
     max_iter = 100
     if (present(max_iterations)) max_iter = max_iterations
     W.create_copy(self)
     eigenvectors.to_unit_matrix
     iter = 0
     do
        iter = iter + 1
        DIE_IF(iter>max_iter,"too many iterations")
        if (iter>max_iter) exit
        tol = accuracy
        if (iter<=3) tol = TOL(1)*(sum(abs(W)) - W.trace)
        done = TRUE
        do i = 1,.dim1
        do j = 1,i-1
           if (abs(W(i,j))<tol) cycle
           done = FALSE
           W.jacobi_rotation(i,j,eigenvectors)      
        end
        end
        done = done AND iter>3
        if (done) exit
     end
     W.put_diagonal_to(eigenvalues)
     W.destroy
   end

!   solve_general_eigenproblem(eigenvalues,left,right,normalize)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "left" and "right" eigenvectors. If "normalize" is present
!   ! and FALSE, the left and right eigenvectors are not automatically
!   ! renormalized so that (left)^T (right) = 1
!      eigenvalues :: VEC{CPX}
!      left,right :: MAT{CPX}
!      normalize :: BIN, optional
!      er,ei,W :: VEC{REAL}*
!      A,le,re :: MAT{REAL}*
!      i,dim,dimW, info :: INT
!      normalise :: BIN
!      dot :: REAL
!      ENSURE(.is_square,"non-square matrix")
!      ENSURE(size(eigenvalues)>=.dim1,"eigenvalue array too small")
!      ENSURE(size(left)>=size(self),"left eigenvector matrix too small")
!      ENSURE(size(right)>=size(self),"right eigenvector matrix too small")
!      dim = .dim1
!      normalise = TRUE
!      if (present(normalize)) normalise = normalize
!      if (self.is_symmetric) then
!         A.create(dim,dim)
!         er.create(dim)
!         .solve_symmetric_eigenproblem(er,A)
!         eigenvalues = er
!         right = A
!         left  = A
!         er.destroy
!         A.destroy
!      else
!         A.create(dim,dim)
!         er.create(dim); ei.create(dim)
!         le.create(dim,dim); re.create(dim,dim)
!         dimW = 8*dim
!         W.create(dimW)
!         A = self
!         ! Solve the eigenvalueproblem
!         call dgeev('V','V',dim,A,dim,er,ei,le,dim,re,dim,W,dimW,info)
!         ENSURE(info==0,"error, info="// trim(info.to_str))
!         ! Search for the complex eigenvalues/vectors
!         i = 1
!         do
!            if (NOT ei(i).is_zero(TOL(20))) then
!               eigenvalues(i)   = cmplx(er(i)  ,ei(i),  kind=CPX_KIND)
!               eigenvalues(i+1) = cmplx(er(i+1),ei(i+1),kind=CPX_KIND)
!               left(:,i)    = cmplx(le(:,i), le(:,i+1),kind=CPX_KIND)
!               left(:,i+1)  = cmplx(le(:,i),-le(:,i+1),kind=CPX_KIND)
!               right(:,i)   = cmplx(re(:,i), re(:,i+1),kind=CPX_KIND)
!               right(:,i+1) = cmplx(re(:,i),-re(:,i+1),kind=CPX_KIND)
!               i = i + 2
!            else
!               eigenvalues(i)   = cmplx(er(i)  , ZERO,  kind=CPX_KIND)
!               left(:,i)    = cmplx(le(:,i),ZERO,kind=CPX_KIND)
!               right(:,i)   = cmplx(re(:,i),ZERO,kind=CPX_KIND)
!               i = i + 1
!            end
!            if (i>dim) exit
!         end
!         W.destroy
!         re.destroy; le.destroy
!         ei.destroy; er.destroy
!         A.destroy
!      end
!      if (normalise) then
!         do i = 1,dim
!            dot = dot_product(left(:,i),right(:,i))
!            dot = ONE/sqrt(dot)
!            left(:,i)  = dot*left(:,i)
!            right(:,i) = dot*right(:,i)
!         end
!      end
!   end

   solve_eigenproblem(eigenvalues,eigenvectors)
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors"
      eigenvalues :: VEC{REAL}
      eigenvectors :: MAT{REAL}
      .solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
   end

   solve_symmetric_eigenproblem(eigenvalues,eigenvectors)
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors"
      eigenvalues :: VEC{REAL}
      eigenvectors :: MAT{REAL}
#ifdef ESSL
      .solve_symm_eigenproblem_ESSL(eigenvalues,eigenvectors)
#else
      .solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors)
#endif
   end

   solve_symm_eigenproblem_ESSL(eigenvalues,eigenvectors) ::: private
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors". ESSL version.
      eigenvalues :: VEC{REAL}
      eigenvectors :: MAT{REAL}
   ENSURE(.is_square,"non-square matrix")
   ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
   ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")
      ap,W :: VEC{REAL}*
      dim :: INT
      dim = .dim1
      ap.create(dim*(dim+1)/2)
      .compress_to_triangle(ap)
      W.create(2*dim)
#ifdef ESSL
      call dspev(21,ap,eigenvalues,eigenvectors,dim,dim,W,2*dim)
#endif
      W.destroy
      ap.destroy
   end

   solve_symm_eigenproblem_LAPACK(eigenvalues,eigenvectors) ::: private
   ! Solve the symmetric eigenproblem for "self", yeilding a vector of
   ! "eigenvalues" and a matrix of "eigenvectors". LAPACK version.
      eigenvalues :: VEC{REAL}
      eigenvectors :: MAT{REAL}
   ENSURE(.is_square,"non-square matrix")
   ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
   ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")
      W :: VEC{REAL}*
      dim,fail,lwork :: INT
      dim = .dim1
      lwork = max(dim*dim,3*dim-1)
      W.create(lwork)
      eigenvectors = self
      fail = 0
#ifndef ESSL
      call dsyev("V","L",dim,eigenvectors,dim,eigenvalues,W,lwork,fail)
#endif
   ENSURE(fail==0,"no solution, error found")
      W.destroy
   end

!  Unused ESSL routines

!   solve_general_eigenproblem(eigenvalues,eigenvectors)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "eigenvectors"
!      eigenvalues :: VEC{CPX}
!      eigenvectors :: MAT{CPX}
!       W :: VEC{REAL}*
!      dim1,dim2,dime,dimv :: INT
!      select :: BIN
!      dim1 = .dim1
!      dim2 = .dim2
!      dime = size(eigenvalues)
!      dimv = size(eigenvectors)
!      ENSURE(dim1==dim2,"non-square matrix")
!      ENSURE(dime>=dim1,"eigenvalue array too small")
!      ENSURE(dimv>=dim1*dim1,"eigenvector matrix too small")
!      W.create(2*dim1)
!      call dgeev(1,self,dim1,eigenvalues,eigenvectors,dim1,select,dim1,W,2*dim1)
!      W.destroy
!   end
!
!   solve_general_eigenproblem(eigenvalues,left,right,normalize)
!   ! Solve the eigenproblem for "self", yeilding a vector of "eigenvalues" and
!   ! a matrix of "left" and "right" eigenvectors. If "normalize" is present
!   ! and FALSE, the left and right eigenvectors are not automatically
!   ! renormalized so that (left)^T (right) = 1.
!   ! NOTE : this routine fails if there are complex eigenvalues. Use the complex
!   ! routine in this case.
!      eigenvalues :: VEC{REAL}, target
!      left,right :: MAT{REAL}, target
!      normalize :: BIN, optional
!      er,ei,W :: VEC{REAL}*
!      A,le,re :: MAT{REAL}*
!      i,dim,dimW, info :: INT
!      normalise :: BIN
!      dot :: REAL
!      ENSURE(.is_square,"non-square matrix")
!      ENSURE(size(eigenvalues)>=.dim1,"eigenvalues array too small")
!      ENSURE(size(left)>=size(self),"left eigenvector matrix too small")
!      ENSURE(size(right)>=size(self),"right eigenvector matrix too small")
!      dim = .dim1
!      normalise = TRUE
!      if (present(normalize)) normalise = normalize
!      if (.is_symmetric) then
!         .solve_symmetric_eigenproblem(eigenvalues,right)
!         left = right
!      else
!         A.create(dim,dim)
!         ei.create(dim)
!         er => eigenvalues
!         le => left
!         re => right
!         dimW = 8*dim
!         W.create(dimW)
!         A = self
!         ! Solve the eigenvalueproblem
!         call dgeev('V','V',dim,A,dim,er,ei,le,dim,re,dim,W,dimW,info)
!         ENSURE(info==0,"error, info="// trim(info.to_str))
!         ! Search for the complex eigenvalues/vectors
!         do i = 1,dim
!            if (NOT ei(i).is_zero(TOL(20))) then
!               DIE("There are complex eigenvalues, use the complex routine")
!            end
!         end
!         W.destroy
!         ei.destroy
!         A.destroy
!      end
!      if (normalise) then
!         do i = 1,dim
!            dot = dot_product(left(:,i),right(:,i))
!            dot = ONE/sqrt(dot)
!            left(:,i)  = dot*left(:,i)
!            right(:,i) = dot*right(:,i)
!         end
!      end
!   end

! ************************
! Linear equation routines
! ************************

   solve_linear_equation(rhs,solution,fail)
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yeilding vector "solution" as the answer
      rhs,solution :: VEC{REAL}
      fail :: BIN, optional
#ifdef ESSL
      .solve_linear_equation_ESSL(rhs,solution)
#else
      .solve_linear_equation_LAPACK(rhs,solution,fail)
#endif
   end

   solve_linear_equation_ESSL(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yeilding vector "solution" as the answer. ESSL version
      rhs, solution :: VEC{REAL}
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim :: INT
      dim = rhs.dim
      LU.create(dim,dim)
      pivot.create(dim)
      LU = self
      solution = rhs
#ifdef ESSL
      call dgef(LU,dim,dim,pivot)
      call dges(LU,dim,dim,pivot,solution,0)
#endif
      pivot.destroy
      LU.destroy
   end

   solve_linear_equation_LAPACK(rhs,solution,fail) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as the RHS vector,
   ! yielding vector "solution" as the answer. LAPACK version.
      rhs, solution :: VEC{REAL}
      fail :: BIN, optional
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim,nrhs,err :: INT
      dim = rhs.dim
      nrhs = 1
      nullify(LU); LU.create(dim,dim)
      nullify(pivot); pivot.create(dim)
      LU = self
      solution = rhs
#ifndef ESSL
      call dgesv(dim,nrhs,LU,dim,pivot,solution,dim,err)
#endif
      if (present(fail)) then
         fail = FALSE
         if (err/=0) fail = TRUE
      else
         ENSURE(err==0,"no solution, error found")
      end
      pivot.destroy
      LU.destroy
   end

   solve_linear_equations(rhs,solution)
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
      rhs, solution :: MAT{REAL}
#ifdef ESSL
      .solve_linear_equations_ESSL(rhs,solution)
#else
      .solve_linear_equations_LAPACK(rhs,solution)
#endif
   end

   solve_linear_equations_ESSL(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
   ! ESSL version.
      rhs, solution :: MAT{REAL}
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim1==.dim2,"rhs incompatible with coefficient matrix")
      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim1,nrhs :: INT
      dim1 = rhs.dim1
      nrhs = rhs.dim2
   ENSURE(nrhs>0,"no rhs vectors")
      LU.create(dim1,dim1)
      pivot.create(dim1)
      LU = self
      solution = rhs
#ifdef ESSL
      call dgef(LU,dim1,dim1,pivot)
      call dgesm("N",LU,dim1,dim1,pivot,solution,dim1,nrhs)
#endif
      pivot.destroy
      LU.destroy
   end

   solve_linear_equations_LAPACK(rhs,solution) ::: private
   ! Solve the linear equations posed by "self", with "rhs" as a matrix of RHS
   ! vectors, yeilding matrix "solution" as a matrix of solution vectors.
   ! LAPACK version
      rhs, solution :: MAT{REAL}
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim1==.dim2,"rhs incompatible with coefficient matrix")
   ENSURE(nrhs>0,"no rhs vectors")
      LU :: MAT{REAL}*
      pivot :: VEC{INT}*
      dim1,nrhs,err :: INT
      dim1 = rhs.dim1
      nrhs = rhs.dim2
      LU.create(dim1,dim1)
      pivot.create(dim1)
      LU = self
      solution = rhs
#ifndef ESSL
      call dgesv(dim1,nrhs,LU,dim1,pivot,solution,dim1,err)
#endif
      pivot.destroy
      LU.destroy
      ENSURE(err==0,"no solution, error found")
   end

   solve_convex_linear_equation(rhs,solution,plist,keep0,keep1,fail)
   ! This routine solves the quadratic minimisation problem:
   !    f(X) = rhs . X  -  HALF * X^T . self . X  |  X>=0
   ! over all the elements in "plist", subject to the constraint that the
   ! "solution" X is positive for all elements in "plist". Any elements of the
   ! "solution" not in "plist" are not constrained to be positive nor do they
   ! participate in the evaluation of the quadratic function f -- they are
   ! usually lagrange multipliers. This routine involves solving reduced linear
   ! equations with "self" as the LHS and "rhs" as the RHS, over all partitions
   ! of the elements in "plist".  If "keep0" is present, then the indices in
   ! this sublist of "plist" must be kept when considering all partitions. If
   ! "keep1" is present, then the indices in this sublist of "plist" must be
   ! kept plus at most one extra index for each index in "keep1", and further,
   ! the positivity constraint is relaxed on these indices. It is an error if
   ! "keep0" and "keep1" are both present. If present, "fail" is set TRUE if no
   ! solutions are found, otherwise the routine terminates with an error.
   ! WARNING: if the dimension of the matrix is too large, this routine will
   ! take a long time.
      rhs,solution :: VEC{REAL}
      plist :: VEC{INT}
      keep0,keep1 :: VEC{INT}, optional
      fail :: BIN, optional
   ENSURE(.is_square,"non-square matrix")
   ENSURE(rhs.dim==.dim1,"incompatible rhs")
   ENSURE(solution.dim==.dim1,"incompatible solution vector")
   ENSURE(plist.dim<=.dim1,"plist to large")
   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
   ENSURE(NOT (present(keep0) AND present(keep1)),"specify only keep0 or keep1, not both")
      pdim,rdim,kdim,k,n,n_combinations :: INT
      ulist,list :: VEC{INT}*
      combination :: MAT{INT}*
      sol,sol0,rhs0 :: VEC{REAL}*
      e,e0 :: REAL
      found_one,even :: BIN
!      if (.dim1==6) then
!      list.create(4)
!      sol.create(.dim1)
!      sol = ZERO
!      sol(1) = 0.3
!      sol(2) = 0.7
!      sol(4) = 0.4
!      sol(5) = 0.6
!      list = [1,2,4,5]
!            e0 = dot_product(rhs(list),sol(list)) &
!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!      print *, "===in MAT, average energy =",e0
!      sol.destroy
!      list.destroy
!      end
!!      if (.dim1==3) then
!!      list.create(2)
!!      sol.create(.dim1)
!!      sol = ZERO
!!      sol(1) = 0.3
!!      sol(2) = 0.7
!!      list = [1,2]
!!            e0 = dot_product(rhs(list),sol(list)) &
!!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!!      print *, "===in MAT, average energy =",e0
!!      sol.destroy
!!      list.destroy
!!      end
      even = FALSE
      if (present(keep0)) then
         ENSURE(keep0.has_all_elements_common_with(plist),"keep0 not a sublist of plist")
         kdim = keep0.dim
         even = kdim.is_even
      end
      if (present(keep1)) then
         ENSURE(keep1.has_all_elements_common_with(plist),"keep1 not a sublist of plist")
         kdim = keep1.dim
         even = kdim.is_even
      end
      pdim = plist.dim
      WARN_IF(pdim>=20,"LHS dimension may be too large")
      found_one = FALSE
      e = huge(ONE)
      sol.create(.dim1)
      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
      ulist.prune(plist)                          ! ulist = all - plist = unconstrained 
    ! print *, "-----------start------------"
    ! print *, "even =",even
    ! print *, "plist:"
    ! print *, plist
    ! print *, "ulist:"
    ! print *, ulist
      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
    ! print *, "---> combinations of length k =", k
         if (present(keep1)) then
            if (k>2*kdim) cycle
         end
         n_combinations = nint(pdim.choose(k)) 
         combination.create(k,n_combinations)         
         plist.make_combinations_of_length(k,combination)
         rdim = k + .dim1 - pdim
         rhs0.create(rdim)
         sol0.create(rdim)
         list.create(rdim)                        ! list = comb(plist) + ulist
         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
    ! print *, "combination:"
    ! print *, combination(:,n)
            if (present(keep1)) then               ! if present, keep only these elements
               if (NOT keep1.has_all_elements_common_with(combination(:,n))) cycle
            end
            if (present(keep0)) then               ! if present, keep only these elements
    ! print *, "keep0:"
    ! print *, keep0
             ! if (NOT keep0.has_all_elements_common_with(combination(:,n))) cycle
               if (NOT keep0.has_elements_common_with(combination(:,n))) cycle
               if (even AND all(combination(:,n)> .dim1/2)) cycle
               if (even AND all(combination(:,n)<=.dim1/2)) cycle
            end
            list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
            list(k+1:) = ulist                    ! Always add the list of unconstrained elements
    ! print *, "list:"
    ! print *, list
    ! print *, "rhs:"
    ! print *, rhs
            rhs0 = rhs(list)
    ! print *, "rhs0:"
    ! print *, rhs0
    ! print *, "lhs0:"
    ! print *, self(list,list)
            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
            sol(list) = sol0
    ! print *, "sol0:"
    ! print *, sol0
    ! print *, "sol:"
    ! print *, sol
            if (NOT present(keep1) AND any(sol(list(1:k))<ZERO)) cycle  ! Unacceptable ..............
            e0 = dot_product(rhs(list),sol(list)) &
               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
    ! print *, "e0 = ",e0
            if (e0>=e) cycle                      ! Found a better solution before
            solution = ZERO                       ! Zero non-"list" solution elements
            solution(list) = sol(list)            ! Keep this solutions
    ! print *, "new solution found:"
    ! print *, solution
            e = e0                                ! Keep this E value
            found_one = TRUE
         end
         list.destroy
         sol0.destroy; rhs0.destroy
         combination.destroy
      end
      ulist.destroy
      sol.destroy
      if (present(fail)) then
         if (NOT found_one) then; fail = TRUE
         else;                    fail = FALSE
         end
      else
         DIE_IF(NOT found_one,"acceptable solution was not found")
      end
   end

!   solve_convex_linear_equation(rhs,solution,plist,keep0,keep1,even,fail)
!   ! This routine solves the quadratic minimisation problem:
!   !    f(X) = rhs . X  -  HALF * X^T . self . X  |  X>=0
!   ! over all the elements in "plist", subject to the constraint that the
!   ! "solution" X is positive for all elements in "plist". Any elements of the
!   ! "solution" not in "plist" are not constrained to be positive nor do they
!   ! participate in the evaluation of the quadratic function f -- they are
!   ! usually lagrange multipliers. This routine involves solving reduced linear
!   ! equations with "self" as the LHS and "rhs" as the RHS, over all partitions
!   ! of the elements in "plist".  If "keep0" is present, then the indices in
!   ! this sublist of "plist" must be kept when considering all partitions. If
!   ! "keep1" is present, then the indices in this sublist of "plist" must be
!   ! kept plus one extra index, when considering the partitions, and further,
!   ! the positivity constraint is relaxed on these indices. It is an error if
!   ! "keep0" and "keep1" are both present. If "even" is present and TRUE then
!   ! "self" must be even dimensioned and the linear equations are considered to
!   ! be a (alpha,beta) direct product -- "plist" refers only to the first half of
!   ! the indices: the remaining indices are obtained from the first half by
!   ! adding .dim/2. The same applies to the indices in "keep0" and "keep1" --
!   ! the remaining indices must be generated. If present, "fail" is set TRUE if
!   ! no solutions are found, otherwise the routine terminates with an error.
!   ! WARNING: if the dimension of the matrix is too large, this routine will
!   ! take a long time.
!      rhs,solution :: VEC{REAL}
!      plist :: VEC{INT}
!      keep0,keep1 :: VEC{INT}, optional
!      even,fail :: BIN, optional
!   ENSURE(.is_square,"non-square matrix")
!   ENSURE(rhs.dim==.dim1,"incompatible rhs")
!   ENSURE(solution.dim==.dim1,"incompatible solution vector")
!   ENSURE(plist.dim<=.dim1,"plist to large")
!   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(NOT (present(keep0) AND present(keep1)),"specify only keep0 or keep1, not both")
!      pdim,pfac,rdim,kdim,k,n,n_combinations :: INT
!      ulist,list :: VEC{INT}*
!      combination :: MAT{INT}*
!      sol,sol0,rhs0 :: VEC{REAL}*
!      e,e0 :: REAL
!      found_one,is_even :: BIN
!      is_even = FALSE
!      if (present(even)) is_even = even
!      pfac = 1
!      if (is_even) then
!         ENSURE(.dim1.is_even,"self not even dimensioned")
!         pfac = 2
!      end
!      if (present(keep0)) then
!         ENSURE(keep0.has_all_elements_common_with(plist),"keep0 not a sublist of plist")
!         kdim = keep0.dim
!      end
!      if (present(keep1)) then
!         ENSURE(keep1.has_all_elements_common_with(plist),"keep1 not a sublist of plist")
!         kdim = keep1.dim
!      end
!      pdim = plist.dim
!      WARN_IF(pdim>=20,"LHS dimension may be too large")
!      found_one = FALSE
!      e = huge(ONE)
!      sol.create(.dim1)
!      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
!      ulist.prune(plist)                          ! ulist = all - plist = unconstrained 
!      print *, "-----------start------------"
!      print *, "plist:"
!      print *, plist
!      print *, "ulist:"
!      print *, ulist
!      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
!      print *, "combinations of length k =", k
!         if (present(keep1)) then
!            if (k/=kdim+1) cycle
!         end
!         n_combinations = nint(pdim.choose(k)) 
!         combination.create(k,n_combinations)         
!         plist.make_combinations_of_length(k,combination)
!         rdim = pfac*k + .dim1 - pfac*pdim
!         rhs0.create(rdim)
!         sol0.create(rdim)
!         list.create(rdim)                        ! list = comb(plist) + ulist
!         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
!      print *, "combination:"
!      print *, combination(:,n)
!            if (present(keep1)) then               ! if present, keep only these elements
!               if (NOT keep1.has_all_elements_common_with(combination(:,n))) cycle
!            end
!            if (present(keep0)) then               ! if present, keep only these elements
!               if (NOT keep0.has_all_elements_common_with(combination(:,n))) cycle
!            end
!            if (is_even) then
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(k+1:) = ulist                    ! Always add the list of unconstrained elements
!            else
!               list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!               list(k+1:) = ulist                    ! Always add the list of unconstrained elements
!            end
!      print *, "list:"
!      print *, list
!            rhs0 = rhs(list)
!            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
!            sol(list) = sol0
!            if (NOT present(keep1) AND any(sol(list(1:k))<ZERO)) cycle  ! Unacceptable ..............
!            e0 = dot_product(rhs(list),sol(list)) &
!               - HALF*dot_product(sol(list),matmul(self(list,list),sol(list)))
!            if (e0>=e) cycle                      ! Found a better solution before
!            solution = ZERO                       ! Zero non-"list" solution elements
!            solution(list) = sol(list)            ! Keep this solutions
!      print *, "new solution found:"
!      print *, solution
!            e = e0                                ! Keep this E value
!            found_one = TRUE
!         end
!         list.destroy
!         sol0.destroy; rhs0.destroy
!         combination.destroy
!      end
!      ulist.destroy
!      sol.destroy
!      if (present(fail)) then
!         if (NOT found_one) then; fail = TRUE
!         else;                    fail = FALSE
!         end
!      else
!         DIE_IF(NOT found_one,"acceptable solution was not found")
!      end
!   end

!   solve_convex_linear_equations(rhs,solution,plist,nlist)
!   ! This routine solves the constrained linear equations with "self" as the LHS
!   ! of the linear equations, "rhs" as the RHS vector, and where the "solution"
!   ! is constrained to have positive values for those elements in "plist", AND
!   ! also "solution" minimises the quadratic problem "rhs.X - HALF*X^T.self.X"
!   ! over the elements in "plist" AND "nlist" of "solution". i.e.
!   ! plist -- positive or constrained elements, for testing
!   ! nlist -- non-positive or non-constrained elements for testing
!   ! Any other elements are non-constrained and non-tested. WARNING: if the
!   ! dimension of the matrix is too large, this routine will take a long time.
!      self :: target
!      rhs,solution :: VEC{REAL}
!      plist,nlist :: VEC{INT}
!   ENSURE(.is_square,"non-square matrix")
!   ENSURE(rhs.dim==.dim1,"incompatible rhs")
!   ENSURE(solution.dim==.dim1,"incompatible solution vector")
!   ENSURE(plist.dim<=.dim1,"plist to large")
!   ENSURE(nlist.dim<=.dim1,"nlist to large")
!   ENSURE(plist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(nlist.all_in_range([1,.dim]),"plist indices out of range")
!   ENSURE(plist.has_no_elements_common_with(nlist),"plist and nlist not disjoint")
!      pdim,rdim,k,n,n_combinations :: INT
!      ulist,tlist,list :: VEC{INT}*
!      combination :: MAT{INT}*
!      sol,sol0,rhs0 :: VEC{REAL}*
!      e,e0 :: REAL
!      found_one :: BIN
!      found_one = FALSE
!      e = huge(ONE)
!      pdim = plist.dim
!      sol.create(.dim1)
!      ulist.create(.dim1); ulist = [(k,k=1,.dim1)]
!      ulist.prune(plist)                          ! ulist = all - plist
!      print *, "-----------start------------"
!      print *, "ulist:"
!      print *, ulist
!      do k = pdim,1,-1 ! Loop over indice groups of length "k" which are non-zero
!      print *, "combinations of length k =", k
!         n_combinations = nint(pdim.choose(k)) 
!         combination.create(k,n_combinations)         
!         plist.make_combinations_of_length(k,combination)
!         rdim = k + .dim1 - pdim
!         rhs0.create(rdim)
!         sol0.create(rdim)
!         list.create(rdim)                        ! list = comb(plist) + ulist
!         tlist.create(k+nlist.dim)
!         do n = 1,n_combinations                  ! Loop over a particular "k" length combo
!            list(1:k)  = combination(:,n)         ! The "list" of non-zero solution elements
!            list(k+1:) = ulist                    ! Add the list of unconstrained elements
!            tlist(1:k) = combination(:,n) 
!            tlist(k+1:)= nlist                    ! test tlist = comb(plist) + nlist
!      print *, "list:"
!      print *, list
!      print *, "tlist:"
!      print *, tlist
!            rhs0 = rhs(list)
!            self(list,list).solve_linear_equation(rhs0,sol0) ! Find the subset solution, "sol"
!      print *, "rhs0:"
!      print *, rhs0
!      print *, "sol0:"
!      print *, sol0
!      sol(list) = sol0
!      print *, "sol:"
!      print *, sol(list)
!            if (any(sol(list(1:k))<ZERO)) cycle        ! Unacceptable ..............
!      print *, "passed +ve test"
!            e0 = dot_product(rhs(tlist),sol(tlist)) &
!               - HALF*dot_product(sol(tlist),matmul(self(tlist,tlist),sol(tlist)))
!      print *, "e0=",e0
!            if (e0>=e) cycle                      ! Found a better solution before
!      print *, "passed e0 test"
!            solution = ZERO                       ! Zero non-"list" solution elements
!            solution(list) = sol(list)            ! Keep this solutions
!            e = e0                                ! Keep this E value
!            found_one = TRUE
!         end
!         tlist.destroy; list.destroy
!         sol0.destroy; rhs0.destroy
!         combination.destroy
!      end
!      print *, "-----------finish------------"
!      ulist.destroy
!      sol.destroy
!    ! if (NOT present(keep)) indices.destroy
!      DIE_IF(NOT found_one,"acceptable solution was not found")
!   end

! **********************************************************
! Matrix functions: square roots, inverses, and exponentials
! **********************************************************

   to_inverse_of(R)
   ! self = (R)^(-1); can have R=self
       R :: MAT{REAL}
#ifdef ESSL
      .to_inverse_of_ESSL(R)
#else
      .to_inverse_of_LAPACK(R)
#endif
   end

   to_inverse_of_ESSL(R) ::: private
   ! self = (R)^(-1); can have R=self. ESSL version.
   ! This ESSL version is untested.
      R :: MAT{REAL}
      W :: MAT{REAL}*
      ipiv :: VEC{INT}*
      d,d2 :: INT
#ifdef ESSL
      rcond :: REAL
      det :: VEC{REAL}(2)
#endif
      ENSURE(.is_square,"not square")
      ENSURE(.is_same_shape_as(R),"not same shape as R")
      d  = size(R,1)
      d2 = d*d
      self = R
      ipiv.create(d)
      W.create(d,d)
#ifdef ESSL
      call dgef(d,d,self,ipiv)
      W(:,1) = ipiv
      call dgeicd(self, d, d, 4, rcond, det, W, d2)
#endif
      W.destroy
      ipiv.destroy
   end

   to_inverse_of_LAPACK(R) ::: private
   ! self = (R)^(-1); can have R=self. LAPACK version.
      R :: MAT{REAL}
   ENSURE(.is_square,"not square")
   ENSURE(.is_same_shape_as(R),"not same shape as R")
      W :: MAT{REAL}*
      ipiv :: VEC{INT}*
      d,d2,fail :: INT
      d  = size(R,1)
      d2 = d*d
      self = R
      ipiv.create(d)
      W.create(d,d)
      fail = 0
#ifndef ESSL
      call dgetrf(d,d,self,d,ipiv,fail)
      ENSURE(fail==0,"failed LU factorisation")
      call dgetri(d,self,d,ipiv,W,d2,fail)
      ENSURE(fail==0,"failed back substitution")
#endif
      ipiv.destroy
      W.destroy
   end

   to_sqrt_of(R) ::: get_from(MAT{INTRINSIC})
   ! self = sqrt(R), cannot have R=self
      R :: MAT{REAL}
   end

   to_inverse_sqrt_of(R) ::: get_from(MAT{INTRINSIC})
   ! self = sqrt(R)^(-1), cannot have R=self
      R :: MAT{REAL}
   end

   to_power_series_inverse_of(S,tol,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the power series inverse square root of "S".
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
      S :: MAT{REAL}
      tol :: REAL, optional
      max_it :: INT, optional
   end

   to_power_series_inv_sqrt_of(S,tol,prefactor,max_it) ::: get_from(MAT{INTRINSIC})
   ! Set self to the inverse square root of "S", a matrix which is required to
   ! have a unit diagonal. The method uses a binomial power series expansion.
   ! If "tol" is present, make sure that the maximum deviation from the exact
   ! answer is less than "tol" times the smallest element of "S". If "max_it"
   ! is present, use this as the maximum number of terms in the power series,
   ! before termination with an error.
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional
   end

   to_power_product_inverse_of(S,tol,prefactor,max_it)
   ! Set self to the inverse of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed by the approximate square root until the result in the unit
   ! matrix, within tolerance "tol" (if present). Finally, to form the inverse,
   ! the inverse square root is squared.
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional
   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")
      n :: INT
      W :: MAT{REAL}*
      .to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
      n = S.dim1
      W.create(n,n); W = self
      .to_product_of(W,W)
      W.destroy
   end

   to_power_product_inv_sqrt_of(S,tol,prefactor,max_it)
   ! Set self to the inverse square root of "S".  If "tol" is present, it is
   ! used to establish the maximum deviation from the unit matrix, in the matrix
   ! product self*S*self. If "prefactor" is present, matrix "S" is multiplied by
   ! it to ensure its eigenvalues are less than one. If "max_it" is present, it
   ! is used as the maximum number of terms in the power product series.  The
   ! method uses a binomial power series expansion of "S": if S = (1 + D) then
   ! approximately S^-1/2 = (1 - 1/2 D + ...). The matrix "S" is iteratively
   ! transformed into a new basis using the approximate square root, until the
   ! result is the unit matrix within tolerance "tol" (if present).
      S :: MAT{REAL}
      tol,prefactor :: REAL, optional
      max_it :: INT, optional
   ENSURE(S.is_square,"S not square")
   ENSURE(.is_same_shape_as(S),"wrong shape")
      D,X :: MAT{REAL}*
      max_iter,n,k :: INT
      eps,prefac :: REAL
      eps = TOL(9)
      if (present(tol)) eps = tol
      max_iter = 100
      if (present(max_it)) max_iter = max_it
      prefac = ONE/FOUR
      if (present(prefactor)) prefac = prefactor
      n = S.dim1
      X.create(n,n)
      D.create(n,n)
      X = prefac*S
      self.to_unit_matrix
      k = 0
      do
         k = k + 1
         D = self
         self = (THREE/TWO)*D
         .plus_scaled_product_of(X,D,fac=-HALF)
         S.change_basis_to(X,self)
         X = prefac*X
         write(*,*) "min,max = ",minval(X),maxval(X)
         if (X.has_unit_diagonal(eps)) exit
         ENSURE(k<=max_iter,"power series too long")
      end
      self = sqrt(prefac)*self
      D.destroy
      X.destroy
   end

   to_exponential_of(X,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix "X" using a power series expansion, self = exp(X),
      X :: MAT{REAL}
      tol :: REAL, optional
   end

   exponentiate_to(U,tol) ::: get_from(MAT{INTRINSIC})
   ! Exponentiate the matrix self using a power series expansion, U = exp(self),
   ! so that the maximum deviation from the exact answer is less than "tol"
   ! if present. WARNING: this does not look correct.
      U :: MAT{REAL}, OUT
      tol :: REAL, IN, optional
   end

   antisymmetric_exponential_to(U,eval,evec) ::: get_from(MAT{INTRINSIC})
   ! Make unitary matrix U = exp(self) where "self" must be antisymmetric.
   ! Uses the formula:  exp A = V (cos P) V^t + V (sin P)/P V^t A
   !                        P = sqrt diag(eig(A^t A))
   ! (c) dylan jayatilaka, university of western australia, 1993
   ! WARNING: Untested in TONTO and looks wrong.
      U :: MAT{REAL}
      evec :: MAT{REAL}*, optional
      eval :: VEC{REAL}*, optional
   end

!  ***********************
!  Spin-orbital operations
!  ***********************

!  Block returning routines

   alpha_alpha result(res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-alpha sector of the matrix
      self :: target
      res :: MAT{REAL}*
   end

   beta_alpha result(res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-alpha sector of the matrix
      self :: target
      res :: MAT{REAL}*
   end

   alpha_beta result(res) ::: get_from(MAT{INTRINSIC})
   ! return the alpha-beta sector of the matrix
      self :: target
      res :: MAT{REAL}*
   end

   beta_beta result(res) ::: get_from(MAT{INTRINSIC})
   ! return the beta-beta sector of the matrix
      self :: target
      res :: MAT{REAL}*
   end

!  Set_to routines

   alpha_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Set the alpha-alpha sector of the matrix to "X"
      X :: MAT{REAL}, IN
   end

   alpha_alpha_set_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Set the alpha-alpha sector of the matrix to "X"
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   beta_alpha_set_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Set the beta-alpha sector of the matrix to "X"
      X :: MAT{REAL}, IN
   end

   beta_alpha_set_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Set the beta-alpha sector of the matrix to "X"
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   alpha_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Set the alpha-beta sector of the matrix to "X"
      X :: MAT{REAL}, IN
   end

   alpha_beta_set_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Set the alpha-beta sector of the matrix to "X"
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   beta_beta_set_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Set the beta-beta sector of the matrix to "X"
      X :: MAT{REAL}, IN
   end

   beta_beta_set_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Set the beta-beta sector of the matrix to "X"
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

!  Put_to routines

   alpha_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Put the alpha-alpha sector of the matrix to "X"
      X :: MAT{REAL}, OUT
   end

   alpha_alpha_put_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Put the alpha-alpha sector of the matrix to "X"
      X :: MAT{REAL}, OUT
      factor :: REAL
   end

   beta_alpha_put_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Put the beta-alpha sector of the matrix to "X"
      X :: MAT{REAL}, OUT
   end

   beta_alpha_put_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Put the beta-alpha sector of the matrix to "X"
      X :: MAT{REAL}, OUT
      factor :: REAL, IN
   end

   alpha_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Put the alpha-beta sector of the matrix to "X"
      X :: MAT{REAL}, OUT
   end

   alpha_beta_put_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Put the alpha-beta sector of the matrix to "X"
      X :: MAT{REAL}, OUT
      factor :: REAL, IN
   end

   beta_beta_put_to(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Put the beta-beta sector of the matrix to "X"
      X :: MAT{REAL}, OUT
   end

   beta_beta_put_to(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Put the beta-beta sector of the matrix to "X"
      X :: MAT{REAL}, OUT
      factor :: REAL, IN
   end

!  plus routines

   alpha_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Add "X" to the alpha-alpha sector of the matrix
      X :: MAT{REAL}, IN
   end

   alpha_alpha_plus(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Add "X" to the alpha-alpha sector of the matrix
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   beta_alpha_plus(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Add "X" to the beta-alpha sector of the matrix
      X :: MAT{REAL}, IN
   end

   beta_alpha_plus(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Add "X" to the beta-alpha sector of the matrix
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   alpha_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Add "X" to the alpha-beta sector of the matrix
      X :: MAT{REAL}, IN
   end

   alpha_beta_plus(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Add "X" to the alpha-beta sector of the matrix
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

   beta_beta_plus(X) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL})
   ! Add "X" to the beta-beta sector of the matrix
      X :: MAT{REAL}, IN
   end

   beta_beta_plus(X,factor) ::: get_from(MAT{INTRINSIC}, X_TYPE=>MAT{REAL}, FACTOR_TYPE=>REAL)
   ! Add "X" to the beta-beta sector of the matrix
      X :: MAT{REAL}, IN
      factor :: REAL, IN
   end

! ***************
! Unit conversion
! ***************

   convert_to(units)
   ! Convert the number "self" in atomic units or generic units to a
   ! new number in "units".
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = units.conversion_factor
      self = self * factor
   end

   convert_from(units)
   ! Convert the number "self" from "units" system to a new number
   ! in atomic units or generic units.  Returns "err" whether it was successful.
      self :: INOUT
      units :: STR, IN
   ENSURE(units.is_known_unit,"unknown units, " // units)
      factor :: REAL
      factor = ONE/(units.conversion_factor)
      self = self * factor
   end

! **************************************************
! Gaussian function rotation representation matrices
! *************************************************

   gaussian_d_xyz_matrix result (dtr)
   ! Return the representation matrix for a d-type xyz product found in gaussian
   ! shells, induced by an xyz rotation matrix "self". The matrix representation
   ! induced is: d = d' * dtr, when the coordinates r of the gaussian shell
   ! functions are written in terms of new coordinates r' as: r = self^T * r'.
      dtr :: MAT{REAL}(6,6)
   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")
      i,i1,i2 :: INT
      sqrt3 :: REAL
      d1 :: VEC{INT}(6)  = (/1,2,3,1,1,2/)
      d2 :: VEC{INT}(6)  = (/1,2,3,2,3,3/)
      sqrt3  = sqrt(THREE)
      do i = 1,6 ! loop on old coordinates
         i1 = d1(i)
         i2 = d2(i)
         dtr(1,i)  = self(1,i1)*self(1,i2)
         dtr(2,i)  = self(2,i1)*self(2,i2)
         dtr(3,i)  = self(3,i1)*self(3,i2)
         dtr(4,i)  = self(1,i1)*self(2,i2) &
                   + self(2,i1)*self(1,i2)
         dtr(5,i)  = self(1,i1)*self(3,i2) &
                   + self(3,i1)*self(1,i2)
         dtr(6,i)  = self(2,i1)*self(3,i2) &
                   + self(3,i1)*self(2,i2)
      end
      dtr(1:6,4:6) = dtr(1:6,4:6)*sqrt3 ! Put in correct normalization for old primitives
      dtr(4:6,1:6) = dtr(4:6,1:6)/sqrt3 ! Put in wrong   normalization for new primitives
   end

   gaussian_f_xyz_matrix result (ftr)
   ! Return the representation matrix for an f xyz product found in gaussian
   ! shells from a p-type xyz matrix
      ftr :: MAT{REAL}(10,10)
   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")
      i,i1,i2,i3 :: INT
      sqrt5,sqrt15 :: REAL
      f1 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,1/)
      f2 :: VEC{INT}(10) = (/1,2,3,1,1,2,2,3,3,2/)
      f3 :: VEC{INT}(10) = (/1,2,3,2,3,1,3,1,2,3/)
      sqrt5  = sqrt(FIVE)
      sqrt15 = sqrt(15d0)
      do i = 1,10
         i1 = f1(i)
         i2 = f2(i)
         i3 = f3(i)
         ftr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)
         ftr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)
         ftr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)
         ftr(4,i)  = self(1,i1)*self(1,i2)*self(2,i3) &
                   + self(1,i1)*self(2,i2)*self(1,i3) &
                   + self(2,i1)*self(1,i2)*self(1,i3)
         ftr(5,i)  = self(1,i1)*self(1,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(1,i3)
         ftr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(1,i3)
         ftr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3) &
                   + self(2,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(2,i2)*self(3,i3)
         ftr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(1,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(1,i3)
         ftr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3) &
                   + self(3,i1)*self(2,i2)*self(3,i3) &
                   + self(3,i1)*self(3,i2)*self(2,i3)
         ftr(10,i) = self(1,i1)*self(2,i2)*self(3,i3) &
                   + self(1,i1)*self(3,i2)*self(2,i3) &
                   + self(2,i1)*self(1,i2)*self(3,i3) &
                   + self(2,i1)*self(3,i2)*self(1,i3) &
                   + self(3,i1)*self(1,i2)*self(2,i3) &
                   + self(3,i1)*self(2,i2)*self(1,i3)
      end
      ftr(1:10, 4:9 ) = ftr(1:10, 4:9 )*sqrt5
      ftr(1:10,10:10) = ftr(1:10,10:10)*sqrt15
      ftr(4:9 , 1:10) = ftr(4:9 , 1:10)/sqrt5
      ftr(10:10,1:10) = ftr(10:10,1:10)/sqrt15
   end

   gaussian_g_xyz_matrix result (gtr)
   ! Return the representation matrix for a g xyz product found in gaussian
   ! shells from a p-type xyz matrix
      gtr :: MAT{REAL}(15,15)
   ENSURE(.is_square,"self not square")
   ENSURE(.dim1==3,"wrong size, self")
      i,i1,i2,i3,i4 :: INT
      sqrt7,sqrt35,sqrt353 :: REAL
      g1 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g2 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,1,1,2,1,2,3/)
      g3 :: VEC{INT}(15) = (/1,2,3,1,1,2,2,3,3,2,3,3,2,1,1/)
      g4 :: VEC{INT}(15) = (/1,2,3,2,3,1,3,1,2,2,3,3,3,3,2/)
      sqrt7  = sqrt(SEVEN)
      sqrt35 = sqrt(35d0)         ! = sqrt(35)
      sqrt353= sqrt35/sqrt(THREE) ! = sqrt(35)/sqrt(3)
      do i = 1,15
         i1 = g1(i)
         i2 = g2(i)
         i3 = g3(i)
         i4 = g4(i)
         gtr(1,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(2,i)  = self(2,i1)*self(2,i2)*self(2,i3)*self(2,i4)
         gtr(3,i)  = self(3,i1)*self(3,i2)*self(3,i3)*self(3,i4)
         gtr(4,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(5,i)  = self(1,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(1,i4)
         gtr(6,i)  = self(1,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(1,i4)
         gtr(7,i)  = self(3,i1)*self(2,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(2,i2)*self(2,i3)*self(3,i4)
         gtr(8,i)  = self(1,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(1,i4)
         gtr(9,i)  = self(2,i1)*self(3,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(3,i2)*self(3,i3)*self(2,i4)
         gtr(10,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(11,i) = self(1,i1)*self(1,i2)*self(3,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(3,i2)*self(1,i3)*self(1,i4)
         gtr(12,i) = self(2,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(2,i4)
         gtr(13,i) = self(1,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(1,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(1,i4)
         gtr(14,i) = self(2,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(2,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(1,i1)*self(2,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(2,i4) &
                   + self(3,i1)*self(2,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(2,i4)
         gtr(15,i) = self(3,i1)*self(3,i2)*self(1,i3)*self(2,i4) &
                   + self(3,i1)*self(3,i2)*self(2,i3)*self(1,i4) &
                   + self(3,i1)*self(1,i2)*self(3,i3)*self(2,i4) &
                   + self(3,i1)*self(1,i2)*self(2,i3)*self(3,i4) &
                   + self(3,i1)*self(2,i2)*self(3,i3)*self(1,i4) &
                   + self(3,i1)*self(2,i2)*self(1,i3)*self(3,i4) &
                   + self(1,i1)*self(3,i2)*self(3,i3)*self(2,i4) &
                   + self(1,i1)*self(3,i2)*self(2,i3)*self(3,i4) &
                   + self(1,i1)*self(2,i2)*self(3,i3)*self(3,i4) &
                   + self(2,i1)*self(3,i2)*self(3,i3)*self(1,i4) &
                   + self(2,i1)*self(3,i2)*self(1,i3)*self(3,i4) &
                   + self(2,i1)*self(1,i2)*self(3,i3)*self(3,i4)
      end
      gtr(1:15, 4:9 ) = gtr(1:15, 4:9 )*sqrt7
      gtr(1:15,10:12) = gtr(1:15,10:12)*sqrt353
      gtr(1:15,13:15) = gtr(1:15,13:15)*sqrt35
      gtr(4:9 , 1:15) = gtr(4:9 , 1:15)/sqrt7
      gtr(10:12,1:15) = gtr(10:12,1:15)/sqrt353
      gtr(13:15,1:15) = gtr(13:15,1:15)/sqrt35
   end

! **********
! Misc stuff
! **********

   make_enclosing_sphere(pos,radius) 
   ! Determine the position and radius of a sphere that encloses all points in
   ! the grid.
     self :: IN
     radius :: REAL, OUT
     pos :: VEC{REAL}(3), OUT
   ENSURE(.dim2==3,"Second dimension of matrix is not 3.")
     diff :: VEC{REAL}(3)
     dist :: REAL
     n,n_pts :: INT
     n_pts = .dim2
     ! Get the centre of the sphere.  Should use a better algorithm than just the
     ! average.
     pos = ZERO
     do n = 1,n_pts
       pos = pos + self(n,:)
     end
     pos = pos / n_pts
     ! The radius is the distance to the furthest point.
     radius = 0
     do n = 1,n_pts
       diff = self(n,:) - pos
       dist = dot_product(diff,diff)
       if (dist > radius) radius = dist
     end
     radius = sqrt(radius)
   end

   make_corresponding_orbitals(left,right,theta,p)
   ! This algorithm from Camp and King, J. Chem Phys. Vol 75(1), pp 268-274.
   ! p is the dimenstion of the first block of the partitioned matrices.
   ! Works best if "left" and "right" matrices are nonzero.
     self :: target
     left,right :: MAT{REAL}, target
     theta :: VEC{REAL}, OUT
      p :: INT, IN
   ENSURE(.is_square,"non-square matrix")
   ENSURE(.is_same_shape_as(right),"right is incompatible")
   ENSURE(.is_same_shape_as(left),"left is incompatible")
   ENSURE(size(theta)==min(.dim1,.dim1-p),"theta has wrong size")
     Vp,Vq,Wp,Wq,M,MWq,Hq,Up,Uq :: MAT{REAL}*
     lambda :: VEC{REAL}*
     minpq,q,n :: INT
     n = .dim1
     q = n - p
     minpq = min(p,q)
     ! I've only tested this for q>p.  Suspect p>q does not work.
     Vp => left(:p,:p)
     Vq => left(p+1:,p+1:)
     Wp => right(:p,:p)
     Wq => right(p+1:,p+1:)
     M  => self(:p,p+1:)
     Up => self(:p,:p)
     Uq => self(p+1:,p+1:)
     right(:p,p+1:)=ZERO
     right(p+1:,:p)=ZERO
     left(:p,p+1:)=ZERO
     left(p+1:,:p)=ZERO
     .zero_small_values(TOL(10))

     lambda.create(q)                       ! get eigenvalues and Wq.
     Hq.create(q,q)
     Hq.to_product_of(M,M,transpose_a=TRUE)
     Hq.solve_eigenproblem(lambda,Wq)
     Hq.destroy

     lambda.reverse_order                   ! get rotation angles, largest first.
     theta = lambda(:minpq)
     lambda.destroy
     theta.zero_small_values(TOL(10))

   ENSURE(minval(theta)>=ZERO,"eigenvalues less than zero!")
   ENSURE(maxval(theta)<=ONE,"eigenvalues more than one!")
     theta = min(theta,ONE)
     theta = max(theta,ZERO)

     Wq.zero_small_values(TOL(10))          ! get Vp
     Wq.reverse_column_order
     MWq.create(p,q)
     MWq.to_product_of(M,Wq)
     Vp = MWq(:p,:p)
     MWq.destroy
     Vp.schmidt_orthonormalise(theta)

     Vq.to_product_of(Uq,Wq)                   ! get Vq
     Vq.reverse_schmidt_orthogonalise

     Wp.to_product_of(Up,Vp,transpose_a=TRUE)  ! get Wp
     Wp.reverse_schmidt_orthogonalise

     theta = sqrt(theta)
     theta = asin(theta)
   end

   schmidt_orthonormalise(lambda)
   ! Schmidt orthonormalise the column vectors in "self".
   ! If the eigenvalue (lambda) of a vector is less than a cutoff, then that
   ! vector is chosen to be an orthonormal component.
   ! Eigenvalues must be sorted largest to smallest.
     self :: target
     lambda :: VEC{REAL}, IN
   ENSURE(size(lambda)>=.dim2,"not enough eigenvalues")
   ENSURE(.dim1>=.dim2,"more vectors than dimension of vector space")
     new,old :: VEC{REAL}*
     fac,norm :: REAL
     dim1,dim2,n,k,x,y,j :: INT
     dim1 = .dim1
     dim2 = .dim2

     y=dim2+1   ! y is set to the first vanishing eigenvalue.
     do x=1,dim2
       if (lambda(x)<TOL(10)) then
         y=x
         exit
       end
     end

     do n = 1,y-1  ! the usual Schmidt orthogonalisation.
        new => self(:,n)
        do k = 1,n-1
           old => self(:,k)
           fac = dot_product(old,new)
           new = new - fac*old
        end
        norm = dot_product(new,new)
        ENSURE(norm>TOL(10),"linear dependence in vector " // n.to_str)
        new = new * (ONE/sqrt(norm))
     end

     do n = y,dim2                       ! make up some orthogonal vectors for
       do j=1,dim1                       ! the vanishing eigenvalues.
         new => self(:,n)
         new = ZERO
         new(j) = ONE
         do k = 1,n-1
            old => self(:,k)
            fac = dot_product(old,new)
            new = new - fac*old
         end
         norm = dot_product(new,new)
         if (norm>TOL(10)) then  ! we have found an orthogonal vector
           new = new * (ONE/sqrt(norm))
           exit
         else                   ! try another
           DIE_IF(j==dim1,"cannot find an orthogonal vector")
         end
       end
     end
   end

   to_multipole_W_translation_mx(R,l_max)
   ! Make the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, due to mistake (?) in Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Set self to zero, mainly for upper triangle
      self = ZERO
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)**j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)**j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   add_multipole_W_translation_mx(R,l_max)
   ! Add the multipole translation matrix W(lm,jk)(R) evaluated at position "R"
   ! where the maximum values of l is "l_max". See the book by Helgaker, Olsen,
   ! and Simons, equations (9.13.58)--(9.13.61) and (9.13.65), pp. 413-414.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.is_square,"self must be square")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong dimension")
      Rc,Rs :: VEC{VEC_{REAL}}*
      Rc_lj,Rs_lj :: VEC{REAL}*
      j,k,jk,l,m,lm,sk,lj,mmk,mpk :: INT
      fac :: REAL
      ! Note R, NOT -R, when comparing to Helgaker's book
      VEC{REAL}:make_R_harmonics(Rc,Rs,R,l_max)
      ! Now make the translation matrix
      jk = 0
      do j = 0,l_max
         sk = 1
         if (j.is_even) sk = -1
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk    ! initially,  (-1)**j
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +        Rc_lj(mmk) ! W^ss
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) -     sk*Rc_lj(mpk) ! W^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) -        Rs_lj(mmk) ! W^cs
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) +     sk*Rs_lj(mpk) ! W^cs
               end
            end
         end
         ! Now do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk    ! initially,  (-1)**j, now continuing on
            fac = ONE
            if (k==0) fac = HALF
            lm = j*j
            do l = j,l_max ! j<=l
               lj = l - j
               Rc_lj => Rc(lj).element
               Rs_lj => Rs(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rs_lj(mmk) ! W^sc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rs_lj(mpk) ! W^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mmk = m - k
                  mpk = m + k
                  if (lj>=abs(mmk)) self(lm,jk) = self(lm,jk) +    fac*Rc_lj(mmk) ! W^cc
                  if (lj>=abs(mpk)) self(lm,jk) = self(lm,jk) + sk*fac*Rc_lj(mpk) ! W^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*(Rc_lj(m-k) + sk*Rc_lj(m+k)) ! W^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) =     -Rs_lj(m-k) + sk*Rs_lj(m+k)  ! W^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*(Rs_lj(m-k) + sk*Rs_lj(m+k)) ! W^sc
      !           if (m<0  AND k<0 ) self(lm,jk) =      Rc_lj(m-k) - sk*Rc_lj(m+k)  ! W^ss
      ! Must deallocate Rc, Rs
      do L = l_max,0,-1
         deallocate(Rs(L).element)
         deallocate(Rc(L).element)
      end
      deallocate(Rs)
      deallocate(Rc)
   end

   to_multipole_T_interaction_mx(R,l_max,j_max)
   ! Make the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)**j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)**j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   add_multipole_T_interaction_mx(R,l_max,j_max)
   ! Add the multipole translation matrix T(lm,jk)(R) evaluated at position "R"
   ! where the maximum value of l and j are, respectoively, "l_max" and "j_max".
   ! See the book by Helgaker, Olsen, and Simons, equation (9.13.75), p. 415.
   ! NOTE: self is created.
      self :: PTR
      R :: VEC{REAL}(3)
      l_max,j_max :: INT
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==(l_max+1)*(l_max+1),"self has wrong 1st (l_max) dimension")
   ENSURE(.dim2==(j_max+1)*(j_max+1),"self has wrong 1st (j_max) dimension")
      Ic,Is :: VEC{VEC_{REAL}}*
      Ic_lj,Is_lj :: VEC{REAL}*
      j,k,jk,sj,l,m,lm,sk,lj,mmk,mpk :: INT
      fac,fk,fm :: REAL
      VEC{REAL}:make_I_harmonics(Ic,Is,R,l_max+j_max)
      jk = 0
      do j = 0,j_max
         sj = -1
         if (j.is_even) sj = 1
         sk = -sj
         ! First do k<0
         do k = -j,-1
            jk = jk + 1
            sk = -sk           ! initially,  (-1)**j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*(-Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^ss
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) - sk*Is_lj(mmk)) ! T^cs
               end
            end
         end
         ! No do k>=0
         do k = 0,j
            jk = jk + 1
            sk = -sk           ! initially,  (-1)**j
            fk = ONE
            if (k==0) fk = HALF
            lm = 0
            do l = 0,l_max
               lj = l + j
               Ic_lj => Ic(lj).element
               Is_lj => Is(lj).element
               ! First do m<0
               do m = -l,-1
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Is_lj(mpk) + sk*Is_lj(mmk)) ! T^sc
               end
               ! Now do m>=0
               do m = 0,l
                  lm = lm + 1
                  mpk = m + k
                  mmk = m - k
                  fm = ONE
                  if (m==0) fm = HALF
                  fac = 2*sj*fm*fk
                  self(lm,jk) = self(lm,jk) + fac*( Ic_lj(mpk) + sk*Ic_lj(mmk)) ! T^cc
               end
            end
         end
      end
      !           if (m>=0 AND k>=0) self(lm,jk) = fac*( Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^cc
      !           if (m>=0 AND k<0 ) self(lm,jk) = fac*( Is_lj(m+k) - sk*Is_lj(m-k)) ! T^cs
      !           if (m<0  AND k>=0) self(lm,jk) = fac*( Is_lj(m+k) + sk*Is_lj(m-k)) ! T^sc
      !           if (m<0  AND k<0 ) self(lm,jk) = fac*(-Ic_lj(m+k) + sk*Ic_lj(m-k)) ! T^ss
      ! Must deallocate Ic, Is
      do L = l_max+j_max,0,-1
         deallocate(Is(L).element)
         deallocate(Ic(L).element)
      end
      deallocate(Is)
      deallocate(Ic)
   end

   to_R_mu_multipole_mx(points,l_max)
   ! Make the R_mu multipole matrix, self(i,j), which is the scaled regular
   ! mu-type solid harmonic evaluated at point P_i = "points(:,i)" for moment
   ! (L,M), where index j is L*L + M + L + 1, and where L is less than "l_max".
   ! This matrix is used to multiply the interaction matrix to evaluate the
   ! potential at the given points P_i from multipoles at Q, 
   !     potential(i) = self * T(Q-P_i) * multipoles(Q). 
   ! Reference: the book by Helgaker, Simons and Olsen, p. 407.
      points :: MAT{REAL}, IN
      l_max :: INT
   ENSURE(points.dim2==3,"wrong 2nd dimension, points arrays")
   ENSURE(l_max>=0,"l_max must be non-negative")
   ENSURE(.dim1==points.dim1,"wrong 1st dimension, self")
   ENSURE(.dim2==(l_max+1)*(l_max+1),"wrong 2nd dimension, self")
      Rm :: VEC{VEC_{VEC_{REAL}}}*
      L,M,lm :: INT
      VEC{REAL}:make_R_mu_harmonics(Rm,points,l_max)
      lm = 0
      do L = 0,l_max
         do M = -L,L ! note the canonoical order here
            lm = lm + 1
            self(:,lm) = Rm(L)[M][:]
         end
      end
      do L = l_max,0,-1
         do M = L,-L,-1
            deallocate(Rm(L)[M].element)
         end
         deallocate(Rm(L).element)
      end
      deallocate(Rm)
   end

!  solve_symm_eigenproblem_SCALAPACK(eigenvalues,eigenvectors) ::: private
!  ! Solve the symmetric eigenproblem for "self", yeilding a vector of
!  ! "eigenvalues" and a matrix of "eigenvectors". SCALAPACK version.
!     eigenvalues :: VEC{REAL}
!     eigenvectors :: MAT{REAL}
!     ENSURE(.is_square,"non-square matrix")
!     ENSURE(eigenvalues.dim>=.dim1,"eigenvalue array too small")
!     ENSURE(size(eigenvectors)>=size(self),"eigenvector matrix too small")
!
!!     W :: VEC{REAL}*
!     lmat :: VEC{REAL}* ! local matrix
!
!     nb, myrow, mycol, nprow, npcol, nlrow, nlcol :: INT
!     desca :: VEC{INT}(50) ! Vector (or matrix side) descriptor array for BLACS
!     i,j,dim,info :: INT
!
!     dim = .dim1
!
!!      lwork :: INT
!!      lwork = max(dim*dim,3*dim-1)
!!      W.create(lwork)
!!      eigenvectors = self
!!      fail = 0
!!#ifndef ESSL
!!      call dsyev("V","L",dim,eigenvectors,dim,eigenvalues,W,lwork,fail)
!!#endif
!!      W.destroy
!
!
!!  n, nb, myrow, mycol, n_local_rows, n_local_cols :: INT
!!  clustersize, np0, mq0, anb,sqnpc,nps,nsygst_lwopt,nsytrd_lwopt,lwork :: INT
!!  localmat :: MAT{REAL}*
!!  desca :: VEC{REAL}(8)
!!  work,gap :: VEC{REAL}*
!!  ifail,iwork,iclustr :: VEC{INT}*
!!  junki :: INT
!!  junkr,abstol,orfac :: REAL
!
!!  call descinit(desca,dim,dim,tp.proc_grid_bs,tp.proc_grid_bs,0,0,tp.blacs_2d_context,nb,info)
!!
!!  ! This is for pdsygvx
!!  liwork = 3 + 5*n
!!  clustersize = 20
!!  nn = max(n,nb,2)
!!  np0 = numroc(nn,nb,0,0,nprow)
!!  mq0 = numroc(nn,nb,0,0,npcol)
!!  anb = pjlaenv(.blacs_2d_context,3,'PDSYTTRD','L',0,0,0,0)
!!  sqnpc = int(sqrt(real(nprow * npcol,kind=REAL_KIND)))
!!  nps = max(numroc(n,1,0,0,sqnpc), 2*anb)
!!  nsygst_lwopt = nb*(2*np0 + nq0 + nb)
!!  nsytrd_lwopt = n + 2*( anb+1 )*( 4*nps+2 ) + ( nps + 3 ) *  nps
!!  lrwork = 5*n + max(5*nn,np0*mq0+2*nb*nb) + iceil(neigvec,nprow*npcol)*nn + (clustersize-1)*n
!!  lrwork >=  max(lrwork, 5*n + nsytrd_lwopt, nsygst_lwopt )
!
!    ! Save typing.
!    nb = tonto_parallel.proc_grid_bs
!    myrow = tonto_parallel.proc_grid_myrow
!    mycol = tonto_parallel.proc_grid_mycol
!    nprow = tonto_parallel.proc_grid_nrow
!    npcol = tonto_parallel.proc_grid_ncol
!    nlrow = tonto_parallel.n_this_row(n)
!    nlcol = tonto_parallel.n_this_col(n)
!
!    ! Allocate local matrix.
!    lmat.create(nlrow,nlcol)
!
!    ! Set local matrix from global matrix on this processor.
!    ! Probably not efficient.
!    do i = 1, dim
!      do j = 1, dim
!         call pdelset(lmat,i,j,desca,self(i,j))
!      end
!    end
!
!!  ifail.create(n))
!!  rwork.create(lrwork))
!!  iwork.create(liwork))
!!  iclustr.create(2*nprow*npcol))
!!  gap.create(nprow*npcol))
!!
!!  abstol = 2*pdlamch('S')
!!  orfac = -1.0d0 ! -ve means use defaults.
!!  call pdsyevx( 'V', 'A', 'L', n, a, 1, 1, desca, 'Z',
!!      'Z', 'Z', 'Z', abstol, neigok, neigvecok, eigvals, orfac, eigvec, 1,
!!                  1, desca, rwork, lrwork, iwork, liwork, ifail,
!!                  iclustr, gap, info )
!!
!!  gap.destroy
!!  iclustr.destroy
!!  iwork.destroy
!!  work.destroy
!!  ifail.destroy
!
!    !ENSURE(info==0,"no solution, error found")
!    ! Copy the local matrix to global matrix on all processors.
!    ! Probably not efficient.
!    do i = 1, dim
!      do j = 1, dim
!        call pdelset('A', ' ',self(i,j),lmat,i,j,desca)
!      end
!    end
!    lmat.destroy
!  end

end
